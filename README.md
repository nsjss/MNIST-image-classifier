# MNIST Neural Network from Scratch

# Overview

This project implements a fully connected neural network from scratch (without using deep learning libraries like TensorFlow or PyTorch) to classify handwritten digits from the MNIST dataset.

The goal is to gain a deep understanding of forward propagation, backpropagation, weight updates, and optimization techniques in neural networks.

# Dataset

The MNIST dataset consists of 60,000 training images and 10,000 test images, each 28Ã—28 pixels in grayscale, representing digits from 0 to 9.

![MNIST_image](https://github.com/user-attachments/assets/a1e43192-1cba-4694-bb8d-299ac3cdf428)

## ðŸš€ Features
- **Two-layer neural network** (input â†’ hidden â†’ output)
- **Forward propagation** with sigmoid and softmax activation
- **Backpropagation** using cross-entropy loss
- **Gradient descent** for weight updates
- **Accuracy evaluation** on test data

## ðŸ“ˆ Results

<img width="577" alt="Screenshot 2024-06-29 at 11 23 46â€¯AM" src="https://github.com/nsjss/MNIST-image-classifier/assets/78367519/dcd065c3-8a84-49b8-a9e8-b53b19a443bf">

We get an accuracy of about 89%

## ðŸ”— References

- **MNIST Dataset
- **Neural Networks and Deep Learning
